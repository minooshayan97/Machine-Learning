{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>525</th>\n",
       "      <th>526</th>\n",
       "      <th>527</th>\n",
       "      <th>528</th>\n",
       "      <th>529</th>\n",
       "      <th>530</th>\n",
       "      <th>531</th>\n",
       "      <th>532</th>\n",
       "      <th>533</th>\n",
       "      <th>534</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.004125</td>\n",
       "      <td>0.254095</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>-0.01037</td>\n",
       "      <td>-0.538509</td>\n",
       "      <td>5.95534</td>\n",
       "      <td>1.04063</td>\n",
       "      <td>-1.37437</td>\n",
       "      <td>-0.10937</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.36</td>\n",
       "      <td>7.170320e+08</td>\n",
       "      <td>0.027384</td>\n",
       "      <td>2.53425</td>\n",
       "      <td>17.3882</td>\n",
       "      <td>8.05589</td>\n",
       "      <td>1.80247</td>\n",
       "      <td>1413310.0</td>\n",
       "      <td>3028080.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.031029</td>\n",
       "      <td>0.193761</td>\n",
       "      <td>0.012918</td>\n",
       "      <td>-0.00237</td>\n",
       "      <td>0.781415</td>\n",
       "      <td>5.18794</td>\n",
       "      <td>0.98963</td>\n",
       "      <td>-0.71937</td>\n",
       "      <td>-0.08737</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.78</td>\n",
       "      <td>7.058540e+08</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>2.51513</td>\n",
       "      <td>16.5914</td>\n",
       "      <td>7.81769</td>\n",
       "      <td>1.52349</td>\n",
       "      <td>1390180.0</td>\n",
       "      <td>3016420.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015678</td>\n",
       "      <td>0.182336</td>\n",
       "      <td>-0.003028</td>\n",
       "      <td>-0.02337</td>\n",
       "      <td>0.881194</td>\n",
       "      <td>5.66530</td>\n",
       "      <td>0.87563</td>\n",
       "      <td>-0.71937</td>\n",
       "      <td>-0.08037</td>\n",
       "      <td>...</td>\n",
       "      <td>1016.16</td>\n",
       "      <td>6.270180e+08</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>2.25959</td>\n",
       "      <td>15.2312</td>\n",
       "      <td>7.11684</td>\n",
       "      <td>1.25860</td>\n",
       "      <td>1234110.0</td>\n",
       "      <td>3004430.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.014525</td>\n",
       "      <td>0.176636</td>\n",
       "      <td>-0.006161</td>\n",
       "      <td>-0.02737</td>\n",
       "      <td>1.024900</td>\n",
       "      <td>6.10968</td>\n",
       "      <td>0.91063</td>\n",
       "      <td>-0.71937</td>\n",
       "      <td>-0.08037</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.61</td>\n",
       "      <td>5.597480e+08</td>\n",
       "      <td>0.007377</td>\n",
       "      <td>2.13924</td>\n",
       "      <td>14.4663</td>\n",
       "      <td>6.70236</td>\n",
       "      <td>1.26643</td>\n",
       "      <td>1102720.0</td>\n",
       "      <td>2992170.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010349</td>\n",
       "      <td>0.179248</td>\n",
       "      <td>-0.008526</td>\n",
       "      <td>-0.02737</td>\n",
       "      <td>0.935697</td>\n",
       "      <td>5.83902</td>\n",
       "      <td>0.91063</td>\n",
       "      <td>-0.75637</td>\n",
       "      <td>-0.08337</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.67</td>\n",
       "      <td>4.844730e+08</td>\n",
       "      <td>0.011448</td>\n",
       "      <td>1.93595</td>\n",
       "      <td>12.5493</td>\n",
       "      <td>6.08647</td>\n",
       "      <td>1.22387</td>\n",
       "      <td>954322.0</td>\n",
       "      <td>2979610.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>40</td>\n",
       "      <td>-0.015981</td>\n",
       "      <td>0.254373</td>\n",
       "      <td>-0.013341</td>\n",
       "      <td>-0.00101</td>\n",
       "      <td>-0.165105</td>\n",
       "      <td>5.15843</td>\n",
       "      <td>1.03999</td>\n",
       "      <td>-1.19301</td>\n",
       "      <td>-0.15801</td>\n",
       "      <td>...</td>\n",
       "      <td>1014.61</td>\n",
       "      <td>3.237410e+09</td>\n",
       "      <td>0.132094</td>\n",
       "      <td>9.48535</td>\n",
       "      <td>73.9901</td>\n",
       "      <td>31.82590</td>\n",
       "      <td>5.16972</td>\n",
       "      <td>6390410.0</td>\n",
       "      <td>398810.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4476</th>\n",
       "      <td>40</td>\n",
       "      <td>-0.008857</td>\n",
       "      <td>0.238946</td>\n",
       "      <td>-0.010767</td>\n",
       "      <td>-0.00901</td>\n",
       "      <td>-0.034522</td>\n",
       "      <td>5.43013</td>\n",
       "      <td>1.01499</td>\n",
       "      <td>-1.10201</td>\n",
       "      <td>-0.14501</td>\n",
       "      <td>...</td>\n",
       "      <td>1016.07</td>\n",
       "      <td>3.156070e+09</td>\n",
       "      <td>0.133406</td>\n",
       "      <td>8.73701</td>\n",
       "      <td>68.4041</td>\n",
       "      <td>29.83820</td>\n",
       "      <td>5.06743</td>\n",
       "      <td>6214830.0</td>\n",
       "      <td>412407.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4477</th>\n",
       "      <td>40</td>\n",
       "      <td>0.024672</td>\n",
       "      <td>0.213325</td>\n",
       "      <td>0.014418</td>\n",
       "      <td>0.01099</td>\n",
       "      <td>0.613841</td>\n",
       "      <td>4.55481</td>\n",
       "      <td>1.01499</td>\n",
       "      <td>-0.57301</td>\n",
       "      <td>-0.10401</td>\n",
       "      <td>...</td>\n",
       "      <td>1016.06</td>\n",
       "      <td>3.052520e+09</td>\n",
       "      <td>0.138525</td>\n",
       "      <td>8.90410</td>\n",
       "      <td>68.5051</td>\n",
       "      <td>30.45150</td>\n",
       "      <td>5.88492</td>\n",
       "      <td>6011070.0</td>\n",
       "      <td>425422.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>40</td>\n",
       "      <td>0.025063</td>\n",
       "      <td>0.212210</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.01299</td>\n",
       "      <td>0.593249</td>\n",
       "      <td>4.58374</td>\n",
       "      <td>0.95799</td>\n",
       "      <td>-0.64101</td>\n",
       "      <td>-0.10001</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.80</td>\n",
       "      <td>3.322710e+09</td>\n",
       "      <td>0.076570</td>\n",
       "      <td>8.97766</td>\n",
       "      <td>72.4431</td>\n",
       "      <td>30.38700</td>\n",
       "      <td>4.43563</td>\n",
       "      <td>6544010.0</td>\n",
       "      <td>439695.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4479</th>\n",
       "      <td>40</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.232580</td>\n",
       "      <td>-0.004537</td>\n",
       "      <td>-0.00501</td>\n",
       "      <td>0.397291</td>\n",
       "      <td>4.82234</td>\n",
       "      <td>1.32099</td>\n",
       "      <td>-0.98601</td>\n",
       "      <td>-0.13101</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.77</td>\n",
       "      <td>3.412910e+09</td>\n",
       "      <td>0.006876</td>\n",
       "      <td>9.20105</td>\n",
       "      <td>75.5608</td>\n",
       "      <td>30.77280</td>\n",
       "      <td>2.52386</td>\n",
       "      <td>6721730.0</td>\n",
       "      <td>454341.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4480 rows × 535 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3        4         5        6        7    \\\n",
       "0       1 -0.004125  0.254095  0.001426 -0.01037 -0.538509  5.95534  1.04063   \n",
       "1       1  0.031029  0.193761  0.012918 -0.00237  0.781415  5.18794  0.98963   \n",
       "2       1  0.015678  0.182336 -0.003028 -0.02337  0.881194  5.66530  0.87563   \n",
       "3       1  0.014525  0.176636 -0.006161 -0.02737  1.024900  6.10968  0.91063   \n",
       "4       1  0.010349  0.179248 -0.008526 -0.02737  0.935697  5.83902  0.91063   \n",
       "...   ...       ...       ...       ...      ...       ...      ...      ...   \n",
       "4475   40 -0.015981  0.254373 -0.013341 -0.00101 -0.165105  5.15843  1.03999   \n",
       "4476   40 -0.008857  0.238946 -0.010767 -0.00901 -0.034522  5.43013  1.01499   \n",
       "4477   40  0.024672  0.213325  0.014418  0.01099  0.613841  4.55481  1.01499   \n",
       "4478   40  0.025063  0.212210  0.015656  0.01299  0.593249  4.58374  0.95799   \n",
       "4479   40  0.002555  0.232580 -0.004537 -0.00501  0.397291  4.82234  1.32099   \n",
       "\n",
       "          8        9    ...      525           526       527      528  \\\n",
       "0    -1.37437 -0.10937  ...  1015.36  7.170320e+08  0.027384  2.53425   \n",
       "1    -0.71937 -0.08737  ...  1015.78  7.058540e+08  0.016947  2.51513   \n",
       "2    -0.71937 -0.08037  ...  1016.16  6.270180e+08  0.008129  2.25959   \n",
       "3    -0.71937 -0.08037  ...  1015.61  5.597480e+08  0.007377  2.13924   \n",
       "4    -0.75637 -0.08337  ...  1015.67  4.844730e+08  0.011448  1.93595   \n",
       "...       ...      ...  ...      ...           ...       ...      ...   \n",
       "4475 -1.19301 -0.15801  ...  1014.61  3.237410e+09  0.132094  9.48535   \n",
       "4476 -1.10201 -0.14501  ...  1016.07  3.156070e+09  0.133406  8.73701   \n",
       "4477 -0.57301 -0.10401  ...  1016.06  3.052520e+09  0.138525  8.90410   \n",
       "4478 -0.64101 -0.10001  ...  1015.80  3.322710e+09  0.076570  8.97766   \n",
       "4479 -0.98601 -0.13101  ...  1015.77  3.412910e+09  0.006876  9.20105   \n",
       "\n",
       "          529       530      531        532        533  534  \n",
       "0     17.3882   8.05589  1.80247  1413310.0  3028080.0    1  \n",
       "1     16.5914   7.81769  1.52349  1390180.0  3016420.0    1  \n",
       "2     15.2312   7.11684  1.25860  1234110.0  3004430.0    1  \n",
       "3     14.4663   6.70236  1.26643  1102720.0  2992170.0    1  \n",
       "4     12.5493   6.08647  1.22387   954322.0  2979610.0    1  \n",
       "...       ...       ...      ...        ...        ...  ...  \n",
       "4475  73.9901  31.82590  5.16972  6390410.0   398810.0    4  \n",
       "4476  68.4041  29.83820  5.06743  6214830.0   412407.0    4  \n",
       "4477  68.5051  30.45150  5.88492  6011070.0   425422.0    4  \n",
       "4478  72.4431  30.38700  4.43563  6544010.0   439695.0    4  \n",
       "4479  75.5608  30.77280  2.52386  6721730.0   454341.0    4  \n",
       "\n",
       "[4480 rows x 535 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data.txt', sep=\"\\t\", header = None, low_memory=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject index (1-40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECG_original_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECG_original_std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECG_original_trimmean25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECG_original_median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>EDA_Functionals_power_Filt2geomean(abs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>EDA_Functionals_power_Filt2harmmean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>EDA_Functionals_power_Filt2mad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>EDA_Functionals_power_Filt2baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>Activity: 1-neutral, 2-emotional, 3-mental and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>535 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0                                 Subject index (1-40)\n",
       "1                                    ECG_original_mean\n",
       "2                                     ECG_original_std\n",
       "3                              ECG_original_trimmean25\n",
       "4                                  ECG_original_median\n",
       "..                                                 ...\n",
       "530            EDA_Functionals_power_Filt2geomean(abs)\n",
       "531                EDA_Functionals_power_Filt2harmmean\n",
       "532                     EDA_Functionals_power_Filt2mad\n",
       "533                EDA_Functionals_power_Filt2baseline\n",
       "534  Activity: 1-neutral, 2-emotional, 3-mental and...\n",
       "\n",
       "[535 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = pd.read_csv('labels.txt', sep=\"\\n\",header =None)\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3536ead89d24>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[417][915] = 2000000\n"
     ]
    }
   ],
   "source": [
    "data[417][915] = 2000000\n",
    "data[417] =pd.to_numeric(data[417])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = data[[i for i in range(1,534)]]\n",
    "y = data[534]\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decission Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf1 = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "clf1.fit(x_train, y_train)\n",
    "clf1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       748\n",
      "           2       1.00      1.00      1.00       757\n",
      "           3       1.00      1.00      1.00       744\n",
      "           4       1.00      1.00      1.00       752\n",
      "\n",
      "    accuracy                           1.00      3001\n",
      "   macro avg       1.00      1.00      1.00      3001\n",
      "weighted avg       1.00      1.00      1.00      3001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_train, clf1.predict(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.94      0.95       372\n",
      "           2       0.87      0.87      0.87       363\n",
      "           3       0.86      0.85      0.85       376\n",
      "           4       0.97      0.99      0.98       368\n",
      "\n",
      "    accuracy                           0.91      1479\n",
      "   macro avg       0.91      0.91      0.91      1479\n",
      "weighted avg       0.91      0.91      0.91      1479\n",
      "\n",
      "[[351   4  17   0]\n",
      " [  4 316  36   7]\n",
      " [ 11  43 319   3]\n",
      " [  1   0   1 366]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = clf1.predict(x_test)\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf2 = RandomForestClassifier(criterion='entropy')\n",
    "clf2.fit(x_train, y_train)\n",
    "clf2.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       748\n",
      "           2       1.00      1.00      1.00       757\n",
      "           3       1.00      1.00      1.00       744\n",
      "           4       1.00      1.00      1.00       752\n",
      "\n",
      "    accuracy                           1.00      3001\n",
      "   macro avg       1.00      1.00      1.00      3001\n",
      "weighted avg       1.00      1.00      1.00      3001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, clf2.predict(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.99      0.99       372\n",
      "           2       0.98      0.99      0.98       363\n",
      "           3       0.98      0.98      0.98       376\n",
      "           4       1.00      1.00      1.00       368\n",
      "\n",
      "    accuracy                           0.99      1479\n",
      "   macro avg       0.99      0.99      0.99      1479\n",
      "weighted avg       0.99      0.99      0.99      1479\n",
      "\n",
      "[[368   0   4   0]\n",
      " [  0 360   3   0]\n",
      " [  0   9 367   0]\n",
      " [  0   0   0 368]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = clf2.predict(x_test)\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mini\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:52:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'objective': 'multi:softprob',\n",
       " 'use_label_encoder': True,\n",
       " 'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bynode': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'enable_categorical': False,\n",
       " 'gamma': 0,\n",
       " 'gpu_id': -1,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': '',\n",
       " 'learning_rate': 0.300000012,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': '()',\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': 8,\n",
       " 'num_parallel_tree': 1,\n",
       " 'predictor': 'auto',\n",
       " 'random_state': 0,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': 1,\n",
       " 'tree_method': 'exact',\n",
       " 'validate_parameters': 1,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "clf3 = xgb.XGBClassifier()\n",
    "clf3.fit(x_train, y_train)\n",
    "clf3.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       748\n",
      "           2       1.00      1.00      1.00       757\n",
      "           3       1.00      1.00      1.00       744\n",
      "           4       1.00      1.00      1.00       752\n",
      "\n",
      "    accuracy                           1.00      3001\n",
      "   macro avg       1.00      1.00      1.00      3001\n",
      "weighted avg       1.00      1.00      1.00      3001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, clf3.predict(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.99      1.00       372\n",
      "           2       0.99      0.99      0.99       363\n",
      "           3       0.98      0.99      0.99       376\n",
      "           4       1.00      1.00      1.00       368\n",
      "\n",
      "    accuracy                           0.99      1479\n",
      "   macro avg       0.99      0.99      0.99      1479\n",
      "weighted avg       0.99      0.99      0.99      1479\n",
      "\n",
      "[[370   0   2   0]\n",
      " [  0 358   4   1]\n",
      " [  0   3 373   0]\n",
      " [  0   0   0 368]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = clf3.predict(x_test)\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf4 = svm.SVC(C=10)\n",
    "clf4.fit(x_train, y_train)\n",
    "clf4.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.82      0.46       748\n",
      "           2       0.34      0.05      0.09       757\n",
      "           3       0.42      0.09      0.14       744\n",
      "           4       0.50      0.57      0.53       752\n",
      "\n",
      "    accuracy                           0.38      3001\n",
      "   macro avg       0.40      0.38      0.31      3001\n",
      "weighted avg       0.40      0.38      0.31      3001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, clf4.predict(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.81      0.46       372\n",
      "           2       0.31      0.05      0.08       363\n",
      "           3       0.36      0.07      0.12       376\n",
      "           4       0.48      0.52      0.50       368\n",
      "\n",
      "    accuracy                           0.36      1479\n",
      "   macro avg       0.37      0.36      0.29      1479\n",
      "weighted avg       0.37      0.36      0.29      1479\n",
      "\n",
      "[[301   8  11  52]\n",
      " [255  17  17  74]\n",
      " [250  14  27  85]\n",
      " [140  16  19 193]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = clf4.predict(x_test)\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Fold Cross Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mini\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:53:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:53:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:53:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:53:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:54:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mini\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:54:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:54:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:54:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:54:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:55:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[[732   3  13   0]\n",
      " [  0 743  14   0]\n",
      " [  4  15 724   1]\n",
      " [  0   0   1 751]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([11.23608565, 10.98093247, 10.8517642 , 11.84373498, 11.62969089]),\n",
       " 'score_time': array([0.03291941, 0.03018832, 0.03020024, 0.03033829, 0.02982163]),\n",
       " 'estimator': (XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "                gamma=0, gpu_id=-1, importance_type=None,\n",
       "                interaction_constraints='', learning_rate=0.300000012,\n",
       "                max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "                monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "                num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "                random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "                subsample=1, tree_method='exact', use_label_encoder=True,\n",
       "                validate_parameters=1, verbosity=None),\n",
       "  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "                gamma=0, gpu_id=-1, importance_type=None,\n",
       "                interaction_constraints='', learning_rate=0.300000012,\n",
       "                max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "                monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "                num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "                random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "                subsample=1, tree_method='exact', use_label_encoder=True,\n",
       "                validate_parameters=1, verbosity=None),\n",
       "  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "                gamma=0, gpu_id=-1, importance_type=None,\n",
       "                interaction_constraints='', learning_rate=0.300000012,\n",
       "                max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "                monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "                num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "                random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "                subsample=1, tree_method='exact', use_label_encoder=True,\n",
       "                validate_parameters=1, verbosity=None),\n",
       "  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "                gamma=0, gpu_id=-1, importance_type=None,\n",
       "                interaction_constraints='', learning_rate=0.300000012,\n",
       "                max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "                monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "                num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "                random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "                subsample=1, tree_method='exact', use_label_encoder=True,\n",
       "                validate_parameters=1, verbosity=None),\n",
       "  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "                gamma=0, gpu_id=-1, importance_type=None,\n",
       "                interaction_constraints='', learning_rate=0.300000012,\n",
       "                max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "                monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "                num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "                random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "                subsample=1, tree_method='exact', use_label_encoder=True,\n",
       "                validate_parameters=1, verbosity=None)),\n",
       " 'test_accuracy': array([0.99168053, 0.98333333, 0.97      , 0.98      , 0.99      ]),\n",
       " 'test_recall_macro': array([0.99163296, 0.98337541, 0.96995452, 0.97999956, 0.98995511]),\n",
       " 'test_precision_macro': array([0.99178291, 0.98338807, 0.97046085, 0.98038136, 0.99009804]),\n",
       " 'test_f1_macro': array([0.99167593, 0.98331102, 0.97009687, 0.98004149, 0.98998755]),\n",
       " 'test_recall_weighted': array([0.99168053, 0.98333333, 0.97      , 0.98      , 0.99      ]),\n",
       " 'test_precision_weighted': array([0.99175466, 0.983498  , 0.9704441 , 0.98046695, 0.99009869]),\n",
       " 'test_f1_weighted': array([0.99168535, 0.98334469, 0.97011084, 0.98008506, 0.99001044])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "scoring = ['accuracy','recall_macro','precision_macro','f1_macro','recall_weighted','precision_weighted','f1_weighted']\n",
    "scores = cross_validate(clf3, x_train, y_train, scoring=scoring, cv=5, return_estimator=True)\n",
    "y_predict = cross_val_predict(clf3, x_train, y_train, cv=5)\n",
    "print(metrics.confusion_matrix(y_train, y_predict))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time\n",
      "11.308441638946533\n",
      "\n",
      "score_time\n",
      "0.030693578720092773\n",
      "\n",
      "test_accuracy\n",
      "0.9830027731558513\n",
      "\n",
      "test_recall_macro\n",
      "0.9829835115004638\n",
      "\n",
      "test_precision_macro\n",
      "0.9832222462418407\n",
      "\n",
      "test_f1_macro\n",
      "0.9830225731153739\n",
      "\n",
      "test_recall_weighted\n",
      "0.9830027731558513\n",
      "\n",
      "test_precision_weighted\n",
      "0.9832524804465852\n",
      "\n",
      "test_f1_weighted\n",
      "0.9830472746431346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for k in scores.keys():\n",
    "    if k=='estimator':\n",
    "        continue\n",
    "    print(k)\n",
    "    print(np.mean(scores[k]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'multi:softprob',\n",
       " 'use_label_encoder': True,\n",
       " 'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bynode': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'enable_categorical': False,\n",
       " 'gamma': 0,\n",
       " 'gpu_id': -1,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': '',\n",
       " 'learning_rate': 0.300000012,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': '()',\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': 8,\n",
       " 'num_parallel_tree': 1,\n",
       " 'predictor': 'auto',\n",
       " 'random_state': 0,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': 1,\n",
       " 'tree_method': 'exact',\n",
       " 'validate_parameters': 1,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = scores['estimator'][1]\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
